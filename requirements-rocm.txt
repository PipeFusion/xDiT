# torch>=2.3.0,

numpy==1.24.4
scipy>=1.8.1
diffusers>=0.30.0
transformers>=4.39.1
sentencepiece>=0.1.99
accelerate==0.33.0
beautifulsoup4>=4.12.3
distvae
ftfy>=6.2.0

# long context attention (pytoch native impl on top of flash attention)
yunchang @ git+https://github.com/yiakwy-xpu-ml-framework-team/xDiT-long-context-attention-fork.git@add_amd_gpu_suppport